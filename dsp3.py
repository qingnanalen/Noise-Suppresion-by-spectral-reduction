# -*- coding: utf-8 -*-
"""DSP3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O9llASbmFDKIDrle72e7gD3jP_4MSLE2
"""

from google.colab import drive
drive.mount('/content/drive')
import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
import math

audio_file_path = '/content/drive/MyDrive/Dataset/recording.wav'  # Replace with the actual file name

# Load the audio file and convert it to a NumPy array
recording, sample_rate = librosa.load(audio_file_path, sr=16000)
recording = recording/ max(recording)

# Now, the 'audio' variable contains the audio data as a NumPy array, and 'sample_rate' contains the sample rate of the audio.
plt.figure(figsize=(14, 4))
librosa.display.waveshow(recording, sr=sample_rate)
plt.xlabel("Time (s)")
plt.title("Audio Waveform without adding noise")
plt.show()

pink_noise = np.random.normal(0, 1, len(recording)).cumsum()
pink_noise -= np.mean(pink_noise)
pink_noise /= 5*np.max(np.abs(pink_noise))

plt.figure(figsize=(14, 4))
librosa.display.waveshow(pink_noise, sr=sample_rate)
plt.xlabel("Time (s)")
plt.title("Audio Waveform for Pink Noise")
plt.show()

noisy_speech = recording + pink_noise
print(max(noisy_speech))
plt.figure(figsize=(14, 4))
librosa.display.waveshow(noisy_speech, sr=sample_rate)
plt.xlabel("Time (s)")
plt.title("Recording Waveform with Pink Noise")
plt.show()

n_fft = 2048
win_length = n_fft
hop_length = win_length // 2
STFT_noisy_speech = librosa.stft(noisy_speech,n_fft=n_fft, win_length = win_length, hop_length = hop_length)
STFT_recording = librosa.stft(recording,n_fft=n_fft, win_length = win_length, hop_length = hop_length)
STFT_pink_noise = librosa.stft(pink_noise,n_fft=n_fft, win_length = win_length, hop_length = hop_length)
print(STFT_noisy_speech.shape, STFT_recording.shape, STFT_pink_noise.shape  )

D1 = librosa.amplitude_to_db(np.abs(STFT_recording), ref=np.max)
D2 = librosa.amplitude_to_db(np.abs(STFT_pink_noise), ref=np.max)
D3 = librosa.amplitude_to_db(np.abs(STFT_noisy_speech), ref=np.max)

librosa.display.specshow(D1, x_axis='time', y_axis='log',sr=sample_rate,hop_length=hop_length)
plt.title('Spectrogram of Recording')
plt.show()
librosa.display.specshow(D2, x_axis='time', y_axis='log',sr=sample_rate,hop_length=hop_length)
plt.title('Spectrogram of Pink Noise')
plt.show()
librosa.display.specshow(D3, x_axis='time', y_axis='log',sr=sample_rate,hop_length=hop_length)
plt.title('Spectrogram of Noisy Recording (Recording plus White Noise)')
plt.show()

plt.figure(figsize=(10, 4))

start_time = 24
end_time = 26

# Find the corresponding sample indices for the specified time range
start_sample = int(start_time * sample_rate)
end_sample = int(end_time * sample_rate)

# Plot the audio waveform for the specified time range
librosa.display.waveshow(recording[start_sample:end_sample], sr=sample_rate, x_axis='s')

# Set the x-axis to show labels every 0.1 second within the range [2, 3]
time_points = [i * 0.1 for i in range(int((end_time - start_time) / 0.1) + 1)]
plt.xticks(time_points, [start_time + t for t in time_points])

plt.xlabel("Time (s)")
plt.title("Audio Waveform (24s to 26s)")
plt.show()

start_time = 24.4
end_time = 25.7
start_sample = int(start_time * sample_rate)
end_sample = int(end_time * sample_rate)

start_frame = librosa.samples_to_frames(start_sample, hop_length=hop_length)
end_frame = librosa.samples_to_frames(end_sample, hop_length=hop_length)
print("Start Frame:", start_frame)
print("End Frame:", end_frame)

#taking the average of noise
STFT_noise = STFT_noisy_speech[:,start_frame:end_frame]
print(STFT_noise)
print(STFT_noise.shape)
#noise_mean = np.mean(STFT_noise,axis=1)
noise_mean = np.mean(np.abs(STFT_pink_noise) ,axis=1)
print(noise_mean)
print(noise_mean.reshape(-1,1).shape)

mag_noise = np.abs(noise_mean)
print(mag_noise)
phase_speech = np.angle(STFT_noisy_speech)
mag_speech_noisy = np.abs(STFT_noisy_speech)
print(mag_speech_noisy)
#initialize magnitude of pure speech
mag_speech = np.zeros(mag_speech_noisy.shape)
print(len(mag_speech_noisy))
print(mag_speech_noisy.shape)

"""# Bias Substraction and Halfwave Rectification"""

mag_speech = mag_speech_noisy - mag_noise.reshape(-1,1)
print(mag_speech)
print(mag_speech.shape)
mag_speech[mag_speech < 0] = 0
print(mag_speech)
print(mag_speech.shape)

D = librosa.amplitude_to_db(mag_speech, ref=np.max)

librosa.display.specshow(D, x_axis='time', y_axis='log',sr=sample_rate,hop_length=hop_length)
plt.title('Spectrogram of Noisy Speech after Bias Subtraction and Rectification')
plt.show()

"""# Residual Noise Reduction"""

residual_noise = mag_speech[:,start_frame:end_frame]
print(residual_noise.shape)
print(residual_noise.shape)
residual_noise = np.max(residual_noise,axis = 1)
print(residual_noise.shape)
print(residual_noise)
print(mag_speech.shape)

mag_speech1 = np.zeros(mag_speech.shape)

for x in range(mag_speech.shape[1]):
  for y in range(mag_speech.shape[0]):
    if x == 0: #initial time frame
      if mag_speech[y][x] < residual_noise[y]:
        mag_speech1[y][x] = min(mag_speech[y][x],mag_speech[y][x+1])
      else:
        mag_speech1[y][x] = mag_speech[y][x]
    elif x == mag_speech.shape[1] - 1: #last time frame
      if mag_speech[y][x] < residual_noise[y]:
        mag_speech1[y][x] = min(mag_speech[y][x],mag_speech[y][x-1])
      else:
        mag_speech1[y][x] = mag_speech[y][x]
    else:
      if mag_speech[y][x] < residual_noise[y]:
        mag_speech1[y][x] = min(mag_speech[y][x],mag_speech[y][x-1],mag_speech[y][x+1])
      else:
        mag_speech1[y][x] = mag_speech[y][x]

print(mag_speech1)
print(mag_speech1.shape)

D = librosa.amplitude_to_db(mag_speech1, ref=np.max)
librosa.display.specshow(D, x_axis='time', y_axis='log',sr=sample_rate,hop_length=hop_length)
plt.title('Spectrogram of Noisy Speech after Residual Noise Reduction')
plt.show()

"""# Additional Signal Attenuation"""

column_noise_mean = noise_mean.reshape((-1,1))
print(column_noise_mean)
print(column_noise_mean.shape)

ratio = np.abs(mag_speech1) / np.abs(column_noise_mean)
print(ratio)
print(ratio.shape)
print(mag_speech1.shape[1])
ratio_vector = np.sum(ratio,axis = 0)
ratio_vector = ratio_vector / (2*np.pi)

T = 20 * np.log10(ratio_vector)
print(T.shape)

c = 0.0316227766
mag_speech2 = np.zeros(mag_speech1.shape)
for x in range(mag_speech1.shape[1]):
  if T[x] >= -12:
    for y in range(mag_speech1.shape[0]):
      mag_speech2[y][x] = mag_speech1[y][x]
  else:
    for z in range(mag_speech1.shape[0]):
      mag_speech2[y][x] = c * mag_speech_noisy[y][x]

D = librosa.amplitude_to_db(mag_speech2, ref=np.max)

librosa.display.specshow(D, x_axis='time', y_axis='log',sr=sample_rate,hop_length=hop_length)
plt.title('Spectrogram of Speech after Additional Signal Attenuation ')
plt.show()

speech = mag_speech2*phase_speech
#print(speech)
reconstructed_speech = librosa.istft(speech,n_fft=n_fft, win_length = win_length, hop_length = hop_length)
plt.figure(figsize=(14, 3.5))
librosa.display.waveshow(recording, sr=sample_rate)
plt.xlabel("Time (s)")
plt.title("Audio Waveform without adding noise")
plt.show()
plt.figure(figsize=(14, 3.5))
librosa.display.waveshow(noisy_speech, sr=sample_rate)
plt.xlabel("Time (s)")
plt.title("Audio Waveform with pink noise")
plt.show()
plt.figure(figsize=(14, 3.5))
librosa.display.waveshow(reconstructed_speech, sr=sample_rate)
plt.xlabel("Time (s)")
plt.title("Audio Waveform after Noise Supression")
plt.show()

print(min(recording))
print(min(noisy_speech))
print(min(reconstructed_speech))

from scipy.io import wavfile
import numpy as np

# Assuming you have modified the audio data and have it in a NumPy array called modified_audio_data
# Convert it to the appropriate PCM format (e.g., int16)
pcm_format = np.int16

# Normalize the audio data to the valid range for the chosen data type
reconstructed_speech = np.int16(reconstructed_speech * np.iinfo(pcm_format).max)

# Specify the path where you want to save the modified audio as a .wav file
output_file_path = 'pure_speech_pink.wav'

# Write the modified audio data to the .wav file
wavfile.write(output_file_path, sample_rate, reconstructed_speech)

pcm_format = np.int16

# Normalize the audio data to the valid range for the chosen data type
reconstructed_speech = np.int16(noisy_speech * np.iinfo(pcm_format).max)

# Specify the path where you want to save the modified audio as a .wav file
output_file_path = 'noisy_recording_pink.wav'

# Write the modified audio data to the .wav file
wavfile.write(output_file_path, sample_rate, reconstructed_speech)